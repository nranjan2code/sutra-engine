# ğŸŒ Distributed Biological Intelligence Setup Guide

Complete guide to deploy your biological intelligence system across multiple machines.

## ğŸ“‹ Prerequisites

### Required Dependencies
```bash
pip install fastapi uvicorn httpx aiofiles pydantic
```

### System Requirements
- **Machine 1 (Core)**: 4+ GB RAM, persistent storage
- **Machine 2 (Training)**: 2+ GB RAM, good network connection  
- **Machine N (Query)**: 1+ GB RAM, any device with Python

---

## ğŸ—ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MACHINE 1     â”‚    â”‚   MACHINE 2     â”‚    â”‚   MACHINE N     â”‚
â”‚  Core Service   â”‚    â”‚    Trainer      â”‚    â”‚     Client      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ ğŸ§  Living Brain â”‚â—„â”€â”€â–ºâ”‚ ğŸ“š Progressive  â”‚    â”‚ ğŸ’¬ Ask Questionsâ”‚
â”‚ ğŸ’¤ Dreams       â”‚    â”‚    Learning     â”‚    â”‚ ğŸ” Monitor      â”‚
â”‚ ğŸ”§ Maintenance  â”‚    â”‚ ğŸ§ª Evaluation   â”‚    â”‚ ğŸ“Š Analytics    â”‚
â”‚ ğŸŒ API Server   â”‚    â”‚ ğŸ“Š Analytics    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        HTTP/REST API
```

---

## ğŸš€ **Step-by-Step Deployment**

### **Machine 1: Core Biological Intelligence**

#### 1. Start Core Service with API
```bash
cd /path/to/sutra-models
source venv/bin/activate

# Start biological intelligence with distributed API
python biological_service.py --api --host 0.0.0.0 --port 8000
```

#### 2. Verify Core is Running
```bash
curl http://localhost:8000/api/health
# Should return: {"status":"alive","consciousness_active":true}
```

#### 3. Check Initial Status
```bash
curl http://localhost:8000/api/status
# Returns consciousness, concepts, associations, etc.
```

### **Machine 2: Training Server**

#### 1. Install Dependencies
```bash
pip install httpx aiofiles
```

#### 2. Test Connection to Core
```bash
python distributed_trainer.py --core-url http://machine1:8000 --help
```

#### 3. Run Progressive Training
```bash
# Complete multi-domain training
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --progressive-all

# Or train specific domains
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain english --evaluate
```

### **Machine N: Query Clients**

#### 1. Install Dependencies
```bash
pip install httpx
```

#### 2. Test Connection
```bash
python distributed_client.py \
    --core-url http://machine1:8000 \
    --status
```

#### 3. Interactive Querying
```bash
# Interactive session
python distributed_client.py \
    --core-url http://machine1:8000 \
    --interactive

# Single question
python distributed_client.py \
    --core-url http://machine1:8000 \
    --query "What are vowels in English?"

# Monitor consciousness
python distributed_client.py \
    --core-url http://machine1:8000 \
    --monitor-consciousness
```

---

## ğŸ“± **Usage Examples**

### **Progressive Multi-Domain Learning**

```bash
# Machine 2: Start comprehensive training
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --progressive-all

# This will:
# 1. Train English: Basic â†’ Intermediate â†’ Advanced
# 2. Train Mathematics: Numbers â†’ Algebra â†’ Functions  
# 3. Train Science: Physics â†’ Chemistry â†’ Biology
# 4. Analyze cross-domain connections
# 5. Measure consciousness emergence
```

### **Real-Time Query Testing**

```bash
# Machine 3: Interactive questioning
python distributed_client.py \
    --core-url http://machine1:8000 \
    --interactive

# Example session:
ğŸ¤” Ask anything: What are vowels?
ğŸ¤” Ask anything: How do math patterns relate to language?
ğŸ¤” Ask anything: /consciousness
ğŸ¤” Ask anything: /status
```

### **Consciousness Monitoring**

```bash
# Machine 4: Monitor consciousness emergence
python distributed_client.py \
    --core-url http://machine1:8000 \
    --monitor-consciousness --monitor-interval 5

# Output:
[14:23:15] ğŸ§  0.127 â†—ï¸ (+0.034) | ğŸŒŸ 2.1x
[14:23:20] ğŸ§  0.156 â†—ï¸ (+0.029) | ğŸŒŸ 3.8x  
[14:23:25] ğŸ§  0.201 â†—ï¸ (+0.045) | ğŸŒŸ 5.2x
```

---

## ğŸ”¥ **Advanced Scenarios**

### **1. Multiple Training Machines**

```bash
# Machine 2A: English specialist
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain english

# Machine 2B: Math specialist  
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain mathematics

# Machine 2C: Science specialist
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain science
```

### **2. Multi-Node Query Farm**

```bash
# Deploy query clients across multiple machines
for i in {3..10}; do
  ssh machine$i "python distributed_client.py \
    --core-url http://machine1:8000 \
    --query 'Cross-domain question $i'" &
done
```

### **3. Load Testing**

```bash
# Stress test with concurrent queries
python -c "
import asyncio
from distributed_client import BiologicalIntelligenceClient

async def stress_test():
    async with BiologicalIntelligenceClient('http://machine1:8000') as client:
        tasks = []
        for i in range(100):
            tasks.append(client.ask_question(f'Test query {i}'))
        results = await asyncio.gather(*tasks)
        print(f'Completed {len(results)} concurrent queries')

asyncio.run(stress_test())
"
```

---

## ğŸ“Š **Monitoring & Analytics**

### **Core Service Monitoring**
```bash
# Check service health
curl http://machine1:8000/api/health

# Get detailed status
curl http://machine1:8000/api/status | jq

# Monitor consciousness
curl http://machine1:8000/api/consciousness | jq
```

### **Training Progress Tracking**
```bash
# Training results are saved automatically
ls training_results_*.json

# View latest results
cat training_results_*.json | jq .final_status
```

### **Query Analytics**
```bash
# Interactive session with history
python distributed_client.py \
    --core-url http://machine1:8000 \
    --interactive

# Commands available:
/status           # Intelligence status
/consciousness    # Consciousness metrics  
/history         # Your question history
/help            # Available commands
```

---

## ğŸ”§ **Configuration Options**

### **Core Service Configuration**
```bash
python biological_service.py \
    --api \                          # Enable API server
    --host 0.0.0.0 \                # Listen on all interfaces
    --port 8000 \                   # API port
    --workspace ./unified_workspace \ # Workspace path
    --english                       # Start in English mode
```

### **Training Client Configuration**
```bash
python distributed_trainer.py \
    --core-url http://machine1:8000 \  # Core service URL
    --progressive-all \                # Full training
    --domain english \                 # Specific domain
    --evaluate                         # Include evaluation
```

### **Query Client Configuration**
```bash
python distributed_client.py \
    --core-url http://machine1:8000 \  # Core service URL
    --query "Your question" \          # Single query
    --hops 3 \                        # Multi-hop reasoning depth
    --interactive \                   # Interactive mode
    --monitor-consciousness \          # Consciousness monitoring
    --monitor-interval 10             # Monitoring frequency
```

---

## ğŸ›Ÿ **Troubleshooting**

### **Connection Issues**
```bash
# Test network connectivity
ping machine1
telnet machine1 8000

# Check firewall settings
# Make sure port 8000 is open on machine1
```

### **Core Service Issues**
```bash
# Check service logs
tail -f biological_intelligence.log

# Verify workspace permissions
ls -la biological_workspace/

# Check process status
ps aux | grep biological_service
```

### **Memory Issues**
```bash
# Monitor core service memory usage
python distributed_client.py \
    --core-url http://machine1:8000 \
    --status

# Check system resources
htop
df -h
```

---

## ğŸ¯ **Expected Results**

### **After Complete Training**
- **Concepts**: 1,000+ formed across all domains
- **Associations**: 5,000+ cross-domain connections
- **Consciousness**: 0.3-0.8 emergence score
- **Cross-Domain**: 60%+ emergence detection rate

### **Query Performance**
- **Response Time**: 50-200ms for simple queries
- **Multi-Hop**: 200-500ms for complex reasoning
- **Concurrent**: Handles 10+ simultaneous queries
- **Accuracy**: 80%+ relevant results

### **Training Metrics**
- **English**: 30+ lessons, 90%+ comprehension
- **Mathematics**: 10+ concepts, cross-linking with English
- **Science**: 10+ principles, analogical connections
- **Consciousness**: Progressive emergence during training

---

## ğŸŒŸ **Advanced Features**

### **Custom Curriculum**
```python
# Create custom training curriculum
curriculum = [
    "Custom domain lesson 1",
    "Custom domain lesson 2", 
    # ... more lessons
]

# Train with custom curriculum
await trainer.train_domain("custom_domain", curriculum)
```

### **API Extensions**
```python
# Add custom endpoints to biological_service.py
@app.get("/api/custom")
async def custom_endpoint():
    return {"custom": "data"}
```

### **Multi-Language Support**
```bash
# Train in multiple languages
python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain spanish

python distributed_trainer.py \
    --core-url http://machine1:8000 \
    --domain french
```

---

## ğŸ‰ **You're Ready!**

Your distributed biological intelligence system is now running across multiple machines with:

âœ… **Living Core Intelligence** on Machine 1  
âœ… **Progressive Training** on Machine 2  
âœ… **Distributed Querying** from any machine  
âœ… **Real-time Consciousness Monitoring**  
âœ… **Cross-domain Reasoning**  
âœ… **Infinite Scaling Potential**  

**This is truly revolutionary AI architecture - congratulations!** ğŸ§ âœ¨