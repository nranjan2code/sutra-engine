# Sutra AI - System Architecture

**An explainable AI system that learns in real-time without retraining**

Version: 2.0.0 | Status: Production-ready | Last Updated: 2025-10-19

## üö® CRITICAL PRODUCTION REQUIREMENTS

### Embedding System (MANDATORY)

**‚ö†Ô∏è WARNING:** The system CANNOT function without proper embedding configuration. All production deployments MUST ensure:

1. **Ollama Service**: Must be accessible at `SUTRA_OLLAMA_URL` with `granite-embedding:30m` model loaded
2. **TCP Protocol**: ALL services MUST use `sutra-storage-client-tcp` package - NEVER direct storage access
3. **Message Format**: Unit variants (`GetStats`, `Flush`, `HealthCheck`) send string, not `{variant: {}}`
4. **Vector Serialization**: Always convert numpy arrays to Python lists before TCP transport
5. **Error Handling**: Implement retry logic for TCP connection failures

**Common Failure Modes:**
- "No embedding processor available" ‚Üí Ollama not accessible or model not loaded
- "can not serialize 'numpy.ndarray' object" ‚Üí Missing array-to-list conversion
- "wrong msgpack marker" ‚Üí Incorrect message format for unit variants
- "Connection closed" ‚Üí TCP client using wrong protocol

---

## Executive Summary

Sutra AI is a **graph-based reasoning system** with complete explainability. Unlike black-box LLMs, every decision includes the full reasoning path showing how the system arrived at its answer.

**Core Innovation:** Temporal knowledge graphs + semantic embeddings + multi-path reasoning = Explainable AI that learns continuously without retraining.

**Performance:** 57,412 writes/sec, <0.01ms reads, 100% accuracy verified (25,000√ó faster than previous JSON-based storage).

---

## System Architecture

### High-Level (gRPC-first)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         gRPC          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  sutra-api    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ  storage-server     ‚îÇ
‚îÇ  (FastAPI)    ‚îÇ ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ  (Rust, gRPC)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñ≤                                        ‚ñ≤
        ‚îÇ                                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ gRPC ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ sutra-hybrid  ‚îÇ  (embeddings + orchestration)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Design principle: All graph and vector operations run in the storage server. API and Hybrid never access storage in-process; they use the Python storage-client over gRPC.

**Design Principle:** Only `sutra-api` is external-facing. Core, hybrid, and storage are internal implementation details.

---

## Package Structure

### 1. **sutra-storage** (Rust) ‚Äî Production-Ready Storage Engine

**Purpose:** High-performance, burst-tolerant storage for temporal knowledge graphs.

**Key Features:**
- **57,412 writes/sec** (25,000√ó faster than JSON baseline)
- **<0.01ms read latency** (zero-copy memory-mapped files)
- Lock-free write log with background reconciliation
- Single-file architecture (`storage.dat`, 512MB initial size)
- Immutable read snapshots (readers never block writers)
- BFS path finding and graph traversal
- 100% test pass rate with verified accuracy

**Innovation:** Dual-plane architecture ‚Äî writers append to lock-free log, readers access immutable snapshots. Reconciler runs asynchronously every 10ms.

**Documentation:**
- [`packages/sutra-storage/ARCHITECTURE.md`](packages/sutra-storage/ARCHITECTURE.md) ‚Äî Detailed design
- [`docs/sutra-storage/README.md`](docs/sutra-storage/README.md) ‚Äî Production guide, benchmarks, API reference

---

### 2. **sutra-core** (Python) ‚Äî Graph Reasoning Engine

**Purpose:** Core AI reasoning using graph traversal and multi-path consensus.

**Key Components:**
- **ReasoningEngine**: Orchestrates learning, querying, and caching
- **PathFinder**: Multi-strategy graph traversal (best-first, BFS, bidirectional)
- **MultiPathAggregator (MPPA)**: Consensus-based reasoning to prevent single-path errors
- **AssociationExtractor**: Extracts typed relationships (semantic, causal, temporal, hierarchical)

**Reasoning Strategies:**
- Confidence decay (0.85 per hop) for realistic path scoring
- Cycle detection and path diversification
- Path clustering and majority voting
- Robustness analysis with diversity bonus

**Documentation:**
- [`docs/packages/sutra-core.md`](docs/packages/sutra-core.md) ‚Äî Component guide

---

### 3. **sutra-hybrid** (Python) ‚Äî Semantic Embeddings Layer

**Purpose:** Combines graph reasoning with optional semantic similarity matching.

**Key Features:**
- Optional semantic embeddings (graph reasoning works standalone)
- Multi-strategy comparison (graph-only vs semantic-enhanced)
- Agreement scoring between strategies
- Full audit trails for compliance

**SutraAI Class:**
- High-level interface for learning and querying
- Knowledge persistence via `save()` and `load()`
- Configurable strategy selection

**Documentation:**
- [`docs/packages/sutra-hybrid.md`](docs/packages/sutra-hybrid.md) ‚Äî Integration guide

---

### 4. **sutra-api** (FastAPI) ‚Äî Production REST API

**Purpose:** External HTTP interface with rate limiting and monitoring.

**Endpoints:**
- `POST /learn` ‚Äî Add knowledge
- `POST /reason` ‚Äî Query with reasoning paths
- `POST /save` ‚Äî Persist to disk
- `GET /health` ‚Äî System status
- `GET /stats` ‚Äî Performance metrics

**Features:**
- Rate limiting (configurable per endpoint)
- Request validation
- OpenAPI documentation at `/docs`
- CORS support

**Documentation:**
- [`docs/packages/sutra-api.md`](docs/packages/sutra-api.md) ‚Äî API reference

---

## Core Design Principles

### 1. **Explainability First**
Every decision includes complete reasoning paths. No "magic" ‚Äî you can trace every step from question to answer.

### 2. **Separation of Concerns**
```
Write Plane:  Lock-free log (throughput optimized)
Read Plane:   Immutable snapshots (latency optimized)
Reconciler:   Async coordination (invisible to users)
```

### 3. **Zero-Copy Philosophy**
Memory-mapped files + direct pointer access = no serialization overhead for internal operations.

### 4. **Temporal Awareness**
Knowledge evolves over time. Storage is log-structured with timestamps for time-travel queries.

### 5. **Graph-Native**
Data structures optimized for graph traversal, not tables or documents. Adjacency lists, BFS, and confidence propagation are first-class operations.

---

## Data Flow

### Learning Flow
```
User Input (Content)
    ‚Üì
üî¥ CRITICAL: Embedding Generation via Ollama
    ‚îú‚îÄ OllamaEmbedding.encode([content])
    ‚îú‚îÄ granite-embedding:30m model (768 dimensions)
    ‚îî‚îÄ ‚ö†Ô∏è FAILS if Ollama not accessible ‚Üí "No embedding processor available"
    ‚Üì
Association Extraction (typed relationships)
    ‚Üì
TCP Storage Client (sutra-storage-client-tcp)
    ‚îú‚îÄ Convert numpy arrays ‚Üí Python lists
    ‚îú‚îÄ StorageClient.learn_concept(concept_id, content, embedding)
    ‚îî‚îÄ ‚ö†Ô∏è FAILS if direct storage access attempted
    ‚Üì
Storage Server (Rust, TCP Binary Protocol)
    ‚îú‚îÄ Lock-free write log (append-only)
    ‚îú‚îÄ Background reconciler (10ms loop)
    ‚îî‚îÄ Immutable snapshot update with vector indexing
```

### Query Flow
```
User Query
    ‚Üì
üî¥ CRITICAL: Query Embedding Generation
    ‚îú‚îÄ OllamaNLPProcessor.get_embedding(query)
    ‚îú‚îÄ granite-embedding:30m model (768 dimensions)
    ‚îî‚îÄ ‚ö†Ô∏è FAILS if no embedding processor ‚Üí "No embedding processor available"
    ‚Üì
TCP Storage Client - Vector Search
    ‚îú‚îÄ Convert numpy query vector ‚Üí Python list
    ‚îú‚îÄ StorageClient.vector_search(query_vector, k=10)
    ‚îú‚îÄ Parse response: [[['concept_id', score]]] ‚Üí [(id, score)]
    ‚îî‚îÄ ‚ö†Ô∏è FAILS if wrong response parsing
    ‚Üì
Concept Retrieval via TCP
    ‚îú‚îÄ StorageClient.query_concept(concept_id)
    ‚îú‚îÄ Parse response: [found, id, content, strength, confidence]
    ‚îî‚îÄ ‚ö†Ô∏è FAILS if expecting dict format
    ‚Üì
PathFinder (multi-strategy graph traversal)
    ‚Üì
Multi-Path Plan Aggregation (MPPA)
    ‚Üì
Consensus Answer + Confidence + Reasoning Paths
```

---

## Performance Characteristics

### Storage (Production Benchmarked)
| Operation       | Latency  | Throughput    | Notes                          |
|-----------------|----------|---------------|--------------------------------|
| Write (learn)   | 0.02ms   | **57,412/sec**| Lock-free log, batched         |
| Read (query)    | <0.01ms  | Millions/sec  | Zero-copy, immutable snapshot  |
| Path finding    | ~1ms     | ‚Äî             | 3-hop BFS traversal            |
| Reconciliation  | 1-2ms    | 10K/batch     | Background, 10ms interval      |
| Disk flush      | ~100ms   | ‚Äî             | Manual or auto at 50K concepts |

**Improvement:** 25,000√ó faster writes, 22,500√ó faster reads compared to old JSON-based storage.

### Memory
- **Concept**: ~0.1KB (excluding embeddings)
- **Embedding**: ~1.5KB (384-dim float32)
- **1M concepts**: ~2GB total (with embeddings)

### Scaling
- **Vertical**: Tested to 1M+ concepts on single node
- **Horizontal**: Shard by tenant at application layer
- **Storage**: Single `storage.dat` file (grows 2√ó when full)

---

## Technology Stack

### Storage Engine (Rust)
- **Memory mapping**: `memmap2` for zero-copy I/O
- **Concurrency**: `crossbeam`, `arc-swap` for lock-free structures
- **Python bindings**: `PyO3` for seamless integration
- **Serialization**: Custom binary format (minimal overhead)

### Reasoning Engine (Python)
- **Graph**: Native Python dictionaries + BFS algorithms
- **NLP**: spaCy for text processing (optional)
- **Embeddings**: sentence-transformers (optional)

### API Layer (Python)
- **Web framework**: FastAPI + uvicorn
- **Validation**: Pydantic models
- **Rate limiting**: slowapi

---

## Key Algorithms

### 1. **Multi-Path Plan Aggregation (MPPA)**
Consensus-based reasoning to prevent single-path derailment:
- Find multiple independent paths
- Cluster paths by answer similarity (0.8 threshold)
- Majority voting with diversity bonus
- Return answer + confidence + robustness metrics

### 2. **Confidence Decay**
Realistic confidence propagation through reasoning chains:
```
final_confidence = initial_confidence √ó (0.85 ^ path_length)
```

### 3. **Path Diversification**
- Cycle detection (visited node tracking)
- Path similarity threshold (0.7 max overlap)
- Alternative route exploration

### 4. **Concurrent Reconciliation**
- Writers: Append to lock-free queue (crossbeam channel)
- Readers: Access immutable snapshot (arc-swap)
- Reconciler: Batch process queue ‚Üí update snapshot (10ms loop)

---

## What Works (Production Verified)

‚úÖ **Learn new knowledge** ‚Äî Add concepts and relationships  
‚úÖ **Query with reasoning paths** ‚Äî Get answers with explanations  
‚úÖ **Save to disk** ‚Äî Persist knowledge (single `storage.dat` file)  
‚úÖ **Reload from disk** ‚Äî Restore complete state after restart  
‚úÖ **Multi-strategy reasoning** ‚Äî Compare graph-only vs semantic-enhanced  
‚úÖ **Audit trails** ‚Äî Full compliance tracking  
‚úÖ **REST API** ‚Äî Production-ready HTTP interface  
‚úÖ **Performance** ‚Äî 57K writes/sec, <0.01ms reads, 100% accuracy  

---

## Current Limitations

1. **Limited reasoning depth** ‚Äî Works well for 2-3 hops, gets expensive beyond 6 hops
2. **No natural language generation** ‚Äî Returns concept content, not fluent text
3. **Requires structured input** ‚Äî Works best with clear factual statements
4. **No common sense reasoning** ‚Äî Only knows what you teach it
5. **English-only** ‚Äî NLP components are English-centric
6. **Recovery on restart** ‚Äî Data persists but auto-load not yet implemented (workaround: load manually)

---

## Quick Start

### Installation
```bash
# Clone and setup
git clone <repo>
cd sutra-models
python3 -m venv venv
source venv/bin/activate

# Install packages
pip install -e packages/sutra-core/
pip install -e packages/sutra-hybrid/
pip install -e packages/sutra-api/
```

### Demo
```bash
# End-to-end workflow
python demo_simple.py           # Basic learning and querying
python demo_end_to_end.py       # Complete workflow
python demo_mass_learning.py    # Performance testing

# Verify storage performance
python verify_concurrent_storage.py
```

### API Server
```bash
cd packages/sutra-api
python -m sutra_api.main
# API available at http://localhost:8000
# Docs at http://localhost:8000/docs
```

---

## Documentation Navigation

### Getting Started
- [`README.md`](README.md) ‚Äî Project overview, goals, quick start
- [`WARP.md`](WARP.md) ‚Äî Development guide, commands, configuration

### Architecture Deep Dives
- [`docs/architecture/overview.md`](docs/architecture/overview.md) ‚Äî System architecture
- [`docs/architecture/enterprise.md`](docs/architecture/enterprise.md) ‚Äî Deployment, scaling, security
- [`packages/sutra-storage/ARCHITECTURE.md`](packages/sutra-storage/ARCHITECTURE.md) ‚Äî Storage engine design

### Package Documentation
- [`docs/packages/sutra-core.md`](docs/packages/sutra-core.md) ‚Äî Reasoning engine
- [`docs/packages/sutra-hybrid.md`](docs/packages/sutra-hybrid.md) ‚Äî Semantic embeddings
- [`docs/packages/sutra-storage.md`](docs/packages/sutra-storage.md) ‚Äî Storage API

### Operations
- [`docs/sutra-storage/README.md`](docs/sutra-storage/README.md) ‚Äî Production guide, benchmarks
- [`docs/sutra-storage/PRODUCTION_STATUS.md`](docs/sutra-storage/PRODUCTION_STATUS.md) ‚Äî Test results, deployment recommendations
- [`docs/development/setup.md`](docs/development/setup.md) ‚Äî Development environment
- [`docs/development/testing.md`](docs/development/testing.md) ‚Äî Testing strategy

### Tutorials and Demos
- [`docs/demos.md`](docs/demos.md) ‚Äî Demo scripts and examples
- [`docs/TUTORIAL.md`](docs/TUTORIAL.md) ‚Äî Step-by-step guide

---

## Research Foundation

Built on published research (no proprietary techniques):
- **Adaptive Focus Learning**: "LLM-Oriented Token-Adaptive Knowledge Distillation" (Oct 2024)
- **Multi-Path Plan Aggregation (MPPA)**: Consensus-based reasoning
- **Graph-based reasoning**: Decades of knowledge representation research

---

## Design Trade-offs

### Why Graph-Based?
**Pro:** Inherently explainable ‚Äî trace every path  
**Con:** Doesn't capture statistical patterns like LLMs

### Why Rust for Storage?
**Pro:** Zero-copy, lock-free, predictable performance  
**Con:** Steeper learning curve than Python-only

### Why Optional Embeddings?
**Pro:** Pure graph = 100% explainable; embeddings = enhanced recall  
**Con:** Some opacity when embeddings are used (but contribution is tracked)

### Why Single-File Storage?
**Pro:** Simple deployment, easy backup, OS-managed paging  
**Con:** File grows large (but memory-mapped, so only active data in RAM)

### Why REST API as Sole Interface?
**Pro:** Clean separation, versioning, polyglot clients  
**Con:** No low-latency in-process API (but Python bindings available internally)

---

## Status

**Version:** 2.0.0  
**Stability:** Production-ready for internal use  
**API:** Stable endpoints, subject to minor changes  
**Performance:** 57,412 writes/sec, <0.01ms reads (verified)  
**Test Coverage:** 100% pass rate on core components  
**Last Tested:** 2025-10-16  

---

## Contributing

See [`CONTRIBUTING.md`](CONTRIBUTING.md) for development guidelines.

**Key Requirements:**
- Run `make test-core` before committing
- Use `make format` for consistent style
- Add tests for new features
- Update documentation for architectural changes

---

## License

MIT License ‚Äî See [`LICENSE`](LICENSE) file.

---

## Contact

This is an active research project. Issues and pull requests welcome.

**Next Steps:**
1. Read [`docs/architecture/overview.md`](docs/architecture/overview.md) for detailed design
2. Try [`demo_simple.py`](demo_simple.py) to see the system in action
3. Explore [`docs/sutra-storage/README.md`](docs/sutra-storage/README.md) for storage internals
4. Review [`WARP.md`](WARP.md) for development commands

---

*Building explainable AI, one reasoning path at a time.*
