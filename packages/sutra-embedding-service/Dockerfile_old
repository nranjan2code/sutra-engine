# Sutra Embedding Service - Uses shared ML base image
# Optimized build using sutra-ml-base foundation to reduce size

ARG SUTRA_VERSION=latest

# Start from shared ML base with all heavy dependencies pre-installed
FROM sutra-ml-base:${SUTRA_VERSION} AS ml-base

# Build stage - Install only service-specific dependencies
FROM ml-base AS builder

# Switch to root to install packages
USER root

# Install service-specific dependencies
COPY packages/sutra-embedding-service/requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# Production stage - Inherit from ML base
FROM ml-base

# Copy service-specific dependencies from builder
COPY --from=builder /opt/venv /opt/venv

# Copy application code (lightweight client)
COPY packages/sutra-embedding-service/main.py .

# Switch to service user (inherited from ml-base)
USER sutra

# Environment configuration for new architecture
ARG SUTRA_EDITION=simple
ENV SUTRA_SERVICE_TYPE=embedding
ENV SUTRA_EDITION=${SUTRA_EDITION}
ENV PORT=8888
ENV LOG_LEVEL=INFO

# Health check using new foundation endpoints
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8888/health').raise_for_status()"

# Expose port  
EXPOSE 8888

# Run using new ML foundation
CMD ["python", "main.py"]