# Getting Started with Sutra

Welcome to Sutra AI! This guide will help you get up and running quickly.

## Quick Links

- **[Quickstart Guide](quickstart.md)** - Get Sutra running in 5 minutes
- **[Editions Overview](editions.md)** - Choose the right edition for your needs
- **[Tutorial](tutorial.md)** - Step-by-step introduction to Sutra's features

## What is Sutra?

Sutra is a domain-specific explainable AI system designed for regulated industries. Unlike general LLMs, Sutra:

- Starts empty and learns from YOUR proprietary data
- Provides complete audit trails for all reasoning
- Delivers explainable results with confidence scores
- Maintains data sovereignty and security

## Editions

Sutra comes in three editions:

- **Simple** - Single-node deployment (8 services)
- **Community** - High-availability embedding (3 replicas + HAProxy)
- **Enterprise** - Distributed grid infrastructure (10 services with sharding)

## Prerequisites

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM minimum (16GB recommended)
- 20GB disk space

## Next Steps

1. Follow the [Quickstart Guide](quickstart.md)
2. Learn about [Editions](editions.md)
3. Try the [Tutorial](tutorial.md)
4. Explore the [Architecture](../architecture/system-overview.md)

## Support

- Issues: [GitHub Issues](https://github.com/nranjan2code/sutra-memory/issues)
- Discussions: [GitHub Discussions](https://github.com/nranjan2code/sutra-memory/discussions)
- Docs: [Full Documentation](../README.md)
